#+begin_export latex
\section{Introduction}
The program \ty{alfy} takes as input a table of match lengths and
subject IDs which was constructed with \ty{prepAlfy}. It returns a
four column table consisting of the start and end of the query
coordinates, the measure of homology, and the subject sequence that
region is most similar to. Figure~\ref{fig:alf} shows an output
example of \ty{alfy}.

\section{Implementation}
The outline of \ty{alfy} contains hooks for imports, functions, and
the logic of the main function.
#+end_export
#+begin_src go <<alfy.go>>=
  package main

  import (
	  //<<Imports, Ch. \ref{ch:alf}>>
  )
  //<<Types, Ch. \ref{ch:alf}>>
  func main() {
	  //<<Main function, Ch. \ref{ch:alf}>>
  }
#+end_src
#+begin_export latex
In the main function we prepare the error handling, declare the
options, set the usage, parse the options and calculate the homology
between the queries and the subject files.
#+end_export
#+begin_src go <<Main function, Ch. \ref{ch:alf}>>=
  //<<Prepare error handling, Ch. \ref{ch:alf}>>
  //<<Declare options, Ch. \ref{ch:alf}>>
  //<<Set usage, Ch. \ref{ch:alf}>>
  //<<Parse options, Ch. \ref{ch:alf}>>
  //<<Parse input file, Ch. \ref{ch:alf}>>
  // <<Iterate over Query and Sequence, Ch. \ref{ch:alf}>>
#+end_src
#+begin_export latex
The error handling is handled by the util function
\ty{PrepareErrorMessages}.
#+end_export
#+begin_src go <<Prepare error handling, Ch. \ref{ch:alf}>>=
  util.PrepareErrorMessages("alfy")
#+end_src
#+begin_export latex
We import \ty{util}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
  "github.com/evolbioinf/alfy/util"
#+end_src
#+begin_export latex
We declare the options for the version.
#+end_export
#+begin_src go <<Declare options, Ch. \ref{ch:alf}>>=
  optV := flag.Bool("v", false, "version")
  optF := flag.String("f", "", "interval file")
  optW := flag.Int("w", 80, "window length")
  optQ := flag.Float64("q", 0.1, "quantile of match length distribution")
#+end_src
#+begin_export latex
We import \ty{flag}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
"flag"
#+end_src
#+begin_export latex
The usage is split into three parts. The usage message, an explanation
of \ty{alfy} and an example command.
#+end_export
#+begin_src go <<Set usage, Ch. \ref{ch:alf}>>=
  u := "alfy [prepAlfy.out]"
  p := "Calculate homology between queries and subjects."
  e := "alfy alfy.in"
  clio.Usage(u, p, e)
#+end_src
#+begin_export latex
We import \ty{clio}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
"github.com/evolbioinf/clio"
#+end_src
#+begin_export latex
We parse the options and respond to the version option, -v and the
interval file, -f.
#+end_export
#+begin_src go <<Parse options, Ch. \ref{ch:alf}>>=
  flag.Parse()
  //<<Respond to -v, Ch. \ref{ch:alf}>>
  //<<Respond to -f, Ch. \ref{ch:alf}>>
#+end_src
#+begin_export latex
If the user requested the version, we call the utility function
\ty{Version} with the program name.
#+end_export
#+begin_src go <<Respond to -v, Ch. \ref{ch:alf}>>=
  if *optV {
	  util.Version("alfy")
  }
#+end_src
#+begin_export latex
We then parse the interval files. If a file was given, we open the
file, check for errors, defer its closure and set the input as a
bufio.Scanner type. If the user did not set an interval file, we read
from standard in, and also set the input as a bufio.Scanner type.
#+end_export
#+begin_src go <<Respond to -f, Ch. \ref{ch:alf}>>=
  var sc *bufio.Scanner
  if *optF != "" {
	  file, err := os.Open(*optF)
	  util.Check(err)
	  defer file.Close()
	  sc = bufio.NewScanner(file)
  } else {
	  sc = bufio.NewScanner(os.Stdin)
  }
#+end_src
#+begin_export latex
We import \ty{os} and \ty{bufio}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
  "os"
  "bufio"
#+end_src
#+begin_export latex
After reading and storing the input we create a new variable of type
Query to hold all the data that is to be parsed. Then we initialize
all required variables and scan the text that has been read into the
bufio Scanner. Only after do we start parsing the input file.
#+end_export
#+begin_src go <<Parse input file, Ch. \ref{ch:alf}>>=
  queries := []*Query{}
  //<<New Query, Sequence and Interval, Ch.\ref{ch:alf}>>
  //<<Iterate over file, Ch. \ref{ch:alf}>>
#+end_src
#+begin_export latex
While parsing the file we skip empty lines, and parse
the two types of headers and the intervals. The interval files
contains two type of headers. The main header, which starts with a \#,
and denotes the start of a query, a secondary header, starting with
$>$, denoting the start of a sequence and the intervals describing the
location of the exact matches and the annotation of the subject IDs.
#+end_export
#+begin_src go <<Iterate over file, Ch. \ref{ch:alf}>>=
  for sc.Scan() {
	  line := sc.Text()
	  //<<Skip empty lines, Ch. \ref{ch:alf}>>
	  if line[0] =='-' {
		  //<<Deal with subject statistics, Ch. \ref{ch:alf}>>
	  } else if line[0] == '#' {
		  //<<Deal with query header, Ch. \ref{ch:alf}>>
	  } else if line[0] == '>' {
		  //<<Deal with sequence header, Ch. \ref{ch:alf}>>
	  } else {
		  //<<Deal with intervals, Ch. \ref{ch:alf}>>
	  }
  }
#+end_src
#+begin_export latex
To conveniently handle the input we create three structure types:
query, sequence and intervals.
#+end_export
#+begin_src go<<Types, Ch. \ref{ch:alf}>>=
  //<<Query file structure, Ch. \ref{ch:alf}>>
  //<<Sequence structure, Ch. \ref{ch:alf}>>
  //<<Interval structure, Ch. \ref{ch:alf}>>
#+end_src
#+begin_export latex
A query has a name and is made up of one or more sequences.
#+end_export
#+begin_src go <<Query file structure, Ch. \ref{ch:alf}>>=
  type Query struct {
	  name string
	  sequences []*Sequence
  }
#+end_src
#+begin_export latex
A sequence in turn, contains a header with the name of the sequence,
its length, and the map between the subject IDs and the subject
sequence names. It is followed by the table of intervals.
#+end_export
#+begin_src go <<Sequence structure, Ch. \ref{ch:alf}>>=
  type Sequence struct {
	  name  string
	  length int
	  subjectNames map[int]string
	  intervals []*Interval
  }
#+end_src
#+begin_export latex
The table of intervals describing the exact matches between the
various subject IDs and each given query sequence are contained in the
Intervals structure type. This contains the start and end of each
interval, the match length at the first position of the interval, and
one or more subject IDs where the exact match was found.
#+end_export
#+begin_src go <<Interval structure, Ch. \ref{ch:alf}>>=
  type Interval struct {
	  start int
	  end int
	  ml int
	  subjectIDs []int
  }
#+end_src
#+begin_export latex
Before parsing the data we create a new Query, Sequence and
Interval. The parsed data will then be appended each of these three
variables.
#+end_export
#+begin_src go <<New Query, Sequence and Interval, Ch.\ref{ch:alf}>>=
  var query *Query
  var sequence *Sequence
  var interval *Interval
  var slen int
  var gc float64
#+end_src
#+begin_export latex
We start parsing the file by skipping empty lines.
#+end_export
#+begin_src go <<Skip empty lines, Ch. \ref{ch:alf}>>=
  if len(line) == 0 {
	  continue
  }
#+end_src
#+begin_export latex
The first line of the input file contain the statistics required for
calculating the threshold between homologous and unique regions. It
contains the cumulative length of the subjects, as well as the
respective GC-content. We split the line into fields, and read and
store these two values from the 2nd and 3rd field, respectively.
#+end_export
#+begin_src go <<Deal with subject statistics, Ch. \ref{ch:alf}>>=
  var err error
  fields := strings.Fields(line)
  slen, err = strconv.Atoi(fields[1])
  if err != nil {
	    log.Fatalf("%q is not a number", fields[1])
  }
  gc, err = strconv.ParseFloat(fields[2], 64)
  if err != nil {
	    log.Fatalf("%q is not a float", fields[2])
  }
#+end_src
#+begin_export latex
Then we deal with the query headers which start with a \# followed by
the query name with no blanks in between. We create a new Query and
set its name as the entire string except the first character which
marks the start of the header. We then append the new query to the
array of all queries.
#+end_export
#+begin_src go <<Deal with query header, Ch. \ref{ch:alf}>>=
  query = new(Query)
  query.name = line[1:]
  queries = append(queries, query)
#+end_src
#+begin_export latex
Inside the query, there are one or more sequences. If the line starts
with a $>$, we create a new sequence and split the line into its
fields. The first two fields corresponds to the sequence name and its
length. The sequence name is a string, so it can be extracted
directly. However to extract the sequence length we need to convert it
to an integer and check for errors. We map the numerical IDs and names
to each other. At the end, we append the sequence to the list of query
sequences.
#+end_export
#+begin_src go <<Deal with sequence header, Ch. \ref{ch:alf}>>=
  var err error
  sequence = new(Sequence)
  fields := strings.Fields(line)
  sequence.name = fields[0][1:]
  sequence.length, err = strconv.Atoi(fields[1])
  if err != nil {
	  log.Fatalf("%q is not a number", fields[1])
  }
  //<<Map subject names to IDs, Ch. \ref{ch:alf}>>
  query.sequences = append(query.sequences, sequence)
#+end_src
#+begin_export latex
We import \ty{log}, \ty{strings} and \ty{strconv}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
  "log"
  "strings"
  "strconv"
#+end_src
#+begin_export latex
To map the subject names and subject IDs we start by checking if the
map is nill. If yes, we construct one. Then we iterate over all
remaining fields and split them into keys, the subject IDs, and
values, the subject names. We add the new pair to the set of subject
names in the sequence.
#+end_export
#+begin_src go <<Map subject names to IDs, Ch. \ref{ch:alf}>>=
  if sequence.subjectNames == nil {
	  sequence.subjectNames = make(map[int]string)
  }
  for i := 2 ; i < len(fields); i++ {
	  arr := strings.Split(fields[i],"=")
	  k, err := strconv.Atoi(arr[0])
	  if err != nil {
		  log.Fatalf("%q is not a number",
			  arr[0])
	  }
	  sequence.subjectNames[k-1] = arr[1]
  }
#+end_src
#+begin_export latex
After parsing the headers, we parse the table of intervals. We start
by creating a new interval. Each row of intervals consists of four
numerical columns. We extract the start, end and match length of each
interval. We convert the string into an integer and check for
errors. After parsing the slice of annotated subject IDs, we append
the new interval to the list of sequence intervals.
#+end_export
#+begin_src go <<Deal with intervals, Ch. \ref{ch:alf}>>=
  var err error
  interval = new(Interval)
  fields := strings.Fields(line)
  interval.start, err = strconv.Atoi(fields[0])
  if err != nil {
	  log.Fatalf("%q is not a number",
		  fields[0])
  }
  interval.end, err = strconv.Atoi(fields[1])
  if err != nil {
	  log.Fatalf("%q is not a number",
		  fields[1])
  }
  interval.ml, err = strconv.Atoi(fields[2])
  if err != nil {
	  log.Fatalf("%q is not a number",
		  fields[2])
  }
  //<<Parse annotated subjects, Ch. \ref{ch:alf}>>
  sequence.intervals = append(sequence.intervals,
	  interval)
#+end_src
#+begin_export latex
Each interval may contain one or more annotated subject IDs. Since
subject IDs are delimited by commas, we split the last field by commas
and then iterate over each of the obtained fields. For each subject
ID, we convert it into an integer, check for errors and append it to
the subject IDs of the interval.
#+end_export
#+begin_src go <<Parse annotated subjects, Ch. \ref{ch:alf}>>=
  arr := strings.Split(fields[3],",")
  for i := 0; i< len(arr); i++ {
	  x, err := strconv.Atoi(arr[i])
	  if err != nil {
		  log.Fatalf("%q is not a number ", arr[i])
	  }
	  interval.subjectIDs =
		  append(interval.subjectIDs, x-1)
  }
#+end_src
#+begin_export latex
\subsection{Score the intervals}
We score the intervals for each query and sequence independently. The
scoring of the intervals is done independently for each query and
sequence. The subject IDs intervals are scored by summing up the match
lengths at every position inside a given window of length $w$. The one
or more subjects IDs with the highest scores are considered to be the
window winner and writen down. Before the sliding window analysis we
unfold the list of parsed intervals into a matrix of match lengths
(~\ref{fig:matrix}). Then the matrix can be scored and the maximum
score picked.
#+end_export
#+begin_src latex
  \begin{figure}
    \begin{center}
      \begin{pspicture}(-1.5,-0.5)(6,2.7)
	% rows m
	\psframe(0,0)(5,2)
	\rput(-0.5,1.8){$s_1$}
	\rput(-0.5,1.25){$s_2$}
	\rput(-0.5,0.8){\vdots}
	\rput(-0.5,0){$s_m$}
	\psline{->}(0,2.15)(5,2.15)
	%column n
	\psline{->}(-0.2,2.15)(-0.2,0)
	\rput(0.5, 2.4){$p_1$}
	\rput(1, 2.4){$p_2$}
	\rput(1.5,2.4){$\cdots$}
	\rput(4.75,2.4){$p_n$}
      \end{pspicture}
    \end{center}
    \caption{The $m$ by $n$ matrix of unfolded matches lengths for all
      positions, $p$, of a given query.}\label{fig:matrix}
  \end{figure}
#+end_src
#+begin_src go <<Iterate over Query and Sequence, Ch. \ref{ch:alf}>>=
  for _, query := range queries {
	  for i, sequence := range query.sequences {
		  //<<Unfold match length intervals, Ch. \ref{ch:alf}>>
		  //<<Calculate t, Ch. \ref{ch:alf}>>
		  //<<Score intervals, Ch. \ref{ch:alf}>>
		  //<<Label windows winner, Ch. \ref{ch:alf}>>
		  //<<Summarize windows, Ch. \ref{ch:alf}>>
		  //<<Prepare output table, Ch. \ref{ch:alf}>>
	  }
  }
#+end_src
#+begin_export latex
To unfold the list of intervals, we first initialize our matrix,
matches, which will contain all matches and then fill it. At the end
we also obtain a list of the largest match length found across all
subject IDs.
#+end_export
#+begin_src go <<Unfold match length intervals, Ch. \ref{ch:alf}>>=
  //<<Create match length matrix, Ch. \ref{ch:alf}>>
  //<<Fill match length matrix, Ch. \ref{ch:alf}>>
  //<<Get maximum matches length, Ch. \ref{ch:alf}>>
  //<<Create array of mismatches, Ch. \ref{ch:alf}>>

#+end_src
#+begin_export latex
The matches matrix is an $m$ by $n$ matrix, where $m$ is the number of
annotated subject IDs and $n$ the length of the query.
#+end_export
#+begin_src go <<Create match length matrix, Ch. \ref{ch:alf}>>=
  m :=  len(sequence.subjectNames)
  n := sequence.length
  matches := make([][]int,m)
  for a := range sequence.subjectNames {
	  matches[a] = make([]int,n)
  }
#+end_src
#+begin_export latex
After initializing the matrix, it is filled with the match lengths
previously parsed. For every interval, we iterate from the beginning
of the match, until the end of the match, given by the starting
position plus the length of the match minus 1. To count the number of
positions we declare a counter $p$. For every position we move to the
right, we increase the counter by one and decrease the match length by
the respective number of positions we have walked so far.

Because each interval may contain several annotations, we also iterate
over all annotated subject IDs for a given interval. This allows us to
save the correct match length in the respective subjectID slice.

Finally, overwrite existing match lengths, if they are smaller than
the incoming match length. Because we are extrapolating match lengths
across the full match, we only care about the greatest one.
#+end_export
#+begin_src go <<Fill match length matrix, Ch. \ref{ch:alf}>>=
  for _, interval := range sequence.intervals {
	  for _, a := range interval.subjectIDs {
		  p := 0
		  start := interval.start
		  end := interval.start+interval.ml-1
		  for b := start ; b<= end; b++ {
			  curr := interval.ml -p
			  if curr > matches[a][b] {
				  matches[a][b] = curr
			  }
			  p++
		  }
	  }
  }
#+end_src
#+begin_export latex
To make it easier to process the matches length information from all
the distinct subject IDs, we construct a new array of maximal matches
length, which is composed of the maximal match length found at each
query position, regardless of the query
#+end_export
#+begin_src go <<Get maximum matches length, Ch. \ref{ch:alf}>>=
  max := make([]int, len(matches[0]))
  maxID := make([][]int, len(matches[0]))
  for b := range matches[0] {
	  for a := range matches {
		  if matches[a][b] > max[b] {
			  max[b] = matches[a][b]
			  maxID[b] = maxID[b][:0]
			  maxID[b] = append(maxID[b],a)
		  } else if matches[a][b] == max[b] {
			  maxID[b] = append(maxID[b],a)
		  }
	  }
  }
#+end_src
#+begin_export latex
To facilitate the count of the mismatches, we create a binary array to
hold the mismatches found in the query sequence. We iterate over the
array of maximal matches lengths, and everytime the match ends we set
that position to 1. A match ends if the match length at the current
position is longer or identical to the one in the previous
position. We skip the first position of the array, since a sequence
cannot start on a mismatch. Additionally the match length cannot be
zero, as that means no match exists in the current position.
#+end_export
#+begin_src go <<Create array of mismatches, Ch. \ref{ch:alf}>>=
    mismatches := make([]int, len(matches[0]))
    for a := 0; a < len(max); a++ {
	    if a == 0 {
		    continue
	    } else if max[a] >= max[a-1] && max[a] != 0 {
		      mismatches[a] = 1
	    }
    }
#+end_src
#+begin_export latex
The threshold number of matches per window of length $w$ is calculated
as \[t=w/q+1\], where $q$ is the quantile of the match length
probability distribution. This can calculated through the quantile of
the shustring probability distribution, as shustrings are just one
greater than a maximal match \cite{hau09:est}. The shustring
probability distribution is a function that takes the the length, $l$,
and GC-content, $gc$, of the set of subjects. Both of these values are
included in the output from \ty{prepAlfy}, and were previously
parsed. Here we use them to calculate the threshold $t$.
#+end_export
#+begin_src go <<Calculate t, Ch. \ref{ch:alf}>>=
  q := sus.Quantile(slen, gc, *optQ) -1
  t := int(math.Round(float64(*optW) /float64(q)))
#+end_src
#+begin_export latex
We import \ty{sus} and \ty{math}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
  "github.com/evolbioinf/sus"
  "math"
#+end_src
#+begin_export latex
The scoring of the subject IDs is done with a sliding window
analysis. We start by defining an slice of scores to hold the length
of each subject ID match fragment. Then we initialize a structure of
type windows that will store the left and right border of each
interval as well as their scores. The window type structure is then
initialized. Then, if the length of the array of matches, a proxy for
the sequence length, is larger than the selected window size, we open
the first window.
#+end_export
#+begin_src go <<Score intervals, Ch. \ref{ch:alf}>>=
    score := make([]int,len(sequence.subjectNames))
    windows := make([][]*Window,len(query.sequences))
    var window *Window
    if len(max) >= *optW {
	    //<<Open first window, Ch. \ref{ch:alf}>>
	    //<<Slide window, Ch. \ref{ch:alf}>>
    }
#+end_src
#+begin_export latex
The window structure holds four parameters. The left and right border
of the interval, the length of the fragment of each subject ID found
in a given window and the corresponding slice of subject IDs.
#+end_export
#+begin_src go <<Types, Ch. \ref{ch:alf}>>=
  type Window struct{
	  start int
	  end int
	  score []int
	  winner []int
  }
#+end_src
#+begin_export latex
When opening the first window we set a counter of mismatches, $nm$, as
well as the left and right border to 0. Then, while the current
position, $r$, is smaller than the window size, we count the number of
base pairs each given subject ID covers, as well as the number of
mismatches contained in the first window.
#+end_export
#+begin_src go <<Open first window, Ch. \ref{ch:alf}>>=
  nm := 0
  l := 0
  r := 0
  for r < *optW {
	  if mismatches[r] == 1 {
		  nm++
	  }
	  for _, Id := range maxID[r] {
		score[Id]++
	   }
	  r++
  }
#+end_src
#+begin_export latex
After opening the first window, we want to slide it across the rest of
the matches. We also check if the intervals are homologous. Homologous
regions contain a low number of mismatches. To keep track of our
opened intervals we creat an open bolean. If the bolean is true we
have an opened interval. If false, no interval is currently opened. At
the end we check if we closed all intervals. If its not the case, we
close it and append the last interval to the slice of windows. We also
track whether the shifting of the window was performed with the
shifted boolean. If the requested window size is the length of the
query, we evaluate whether this single interval is homologous. If the
window has been shifted, and thus the right border matches the length
of the query, we skip this step.
#+end_export
#+begin_src go <<Slide window, Ch. \ref{ch:alf}>>=
  open := false
  prev := maxID[r-1]
  shifted := false
  for r < len(max) {
	  shifted = true
	  //<<Check if homologous or unique, Ch. \ref{ch:alf}>>
	  //<<Shift window, Ch. \ref{ch:alf}>>
  }
  if !shifted && r == len(max) {
	  //<<Store single interval, Ch. \ref{ch:alf}>>
  }
  if open {
	  windows[i] = append(windows[i], window)
  }
#+end_src
#+begin_export latex
To check for homology we compare the number of mismatches found with
the calculated threshold. If the number of mismatches found is smaller
than the calculated treshold, then we are standing at a region with
homology signal. Otherwise, we close potentially open homologous
intervals.
#+end_export 
#+begin_src go <<Check if homologous or unique, Ch. \ref{ch:alf}>>=
  if nm < t {
	  //<<Open homologous interval, Ch. \ref{ch:alf}>>
  } else if open && window.end < l  {
	  open = false
	  windows[i] = append(windows[i],window)
  }
#+end_src
#+begin_export latex
When finding an homologous region there are two options. If an
interval is already previously opened we evaluate the slice of subject
IDs, to see if we can expand a previous interval or need to create a
new one. If no interval is open, we create a new interval, a new array
of scores and update the left and right border with the current
coordinates. The variable open is then set to true.
#+end_export
#+begin_src go <<Open homologous interval, Ch. \ref{ch:alf}>>=
  if open {
	  //<<Check window IDs, Ch. \ref{ch:alf}>>
  } else {
	  window = new(Window)
	  window.score = make([]int, len(score))
	  copy(window.score, score)
	  window.start = l
	  window.end = r
	  open = true
  }
#+end_src
#+begin_export latex
To evaluate whether we are expanding or storing a new interval we look
a the slice of subject IDs. If the slice is identical we can expand
the current interval. Otherwise, we store the information regarding
the opened interval and create a new one.
#+end_export
#+begin_src go <<Check window IDs, Ch. \ref{ch:alf}>>=
  if slices.Equal(prev, maxID[r]) {
	  window.end = r
  } else {
	  windows[i] = append(windows[i],window)
	  window = new(Window)
	  window.score = make([]int, len(score))
	  copy(window.score, score)
	  window.start = l
	  window.end = r
  }
#+end_src
#+begin_export latex
If the requested window is the size of the query we only need to
evaluate whether this region is homologous or not. If it is homologous
we create a new window and store the corresponding information to it.
Since r is 0-based, but the length of query is 1-based, we subtract -1
to the right border. This avoids going out of range.
#+end_export
#+begin_src go <<Store single interval, Ch. \ref{ch:alf}>>=
  if nm < t {
	  window = new(Window)
	  window.score = make([]int, len(score))
	  copy(window.score, score)
	  window.start = l
	  window.end = r-1
	  windows[i] = append(windows[i],window)
  }
#+end_src
#+begin_export latex
Before shifting the window we need to update the number of mismatches
and the subject ID score. We also update the slice of subject IDs
stored in the prev variable. Then we shift the window by one base
pair.
#+end_export
#+begin_src go <<Shift window, Ch. \ref{ch:alf}>>=
  //<<Update nm counter, Ch. \ref{ch:alf}>>
  //<<Update score counter, Ch. \ref{ch:alf}>>
  prev = maxID[r]
  l++
  r++
#+end_src
#+begin_export latex
To update the number of mismatches we check whether we are standing
the end or the start of a new mismatch. If the left border is
currently standing at a mismatch, we decrease the number of mismatches
per one. If the new right includes a new mismatch we increase the
counter by one.
#+end_export
#+begin_src go <<Update nm counter, Ch. \ref{ch:alf}>>=
  if mismatches[l] == 1 {
	  nm--
  }
  if mismatches[r] == 1 {
	  nm++
  }
#+end_src
#+begin_export latex
Likewise, we also need to update the scores of the subject IDs. We
decrease the counter of subject IDs for all subjects located at the
left border, and increase by one for all subject IDs located at the
right border.
#+end_export
#+begin_src go <<Update score counter, Ch. \ref{ch:alf}>>=
  for _, a := range maxID[l] {
	  score[a]--
  }
  if r< len(max)-1 {
	  for _, a := range maxID[r] {
		  score[a]++
	  }
  }
#+end_src
#+begin_export latex
\subsection{Label and score windows}
After the sliding window analysis, the next step is to label each
window with the winner subject IDs, merge adjacent windows with the
same label, and to calculate the number of mismatches found in that
specific window.

To select the winner of the window we use the previously calculated
score. This score reflects the number of base pairs, for a given
windows, that the subject ID encompasses. Therefore, subject IDs with
longer matches will be favoured.

We start by iterating over the stored slices of windows, and identify
the subject ID with the largest calculated score.
#+end_export
#+begin_src go <<Label windows winner, Ch. \ref{ch:alf}>>=
  for _, win := range windows {
	  for _, w := range win {
		  max := 0
		  sID := make([]int,0)
		  for a, count := range w.score {
			  if count > max {
				  max = count
				  sID = sID[:0]
				  sID = append(sID,a)					
			  } else if count == max {
				  sID = append(sID,a)
			  }
		  }
		  w.winner = make([]int,len(sID))
		  copy(w.winner, sID)
	  }
  }
#+end_src
#+begin_export latex
After selecting a winner, we can now merge adjacent windows that have
the same annotation. For this we go through the existing windows, and
if two adjacent windows share the same winner we merge them and update
the left and right border of the intervals. The final set of intervals
are stored in a final structure called summary.
#+end_export
#+begin_src go <<Summarize windows, Ch. \ref{ch:alf}>>=
  var summary []*Summary
  //<<Merge adjacent windows, Ch. \ref{ch:alf}>>
  //<<Calculate window mismatches, Ch. \ref{ch:alf}>>
#+end_src
#+begin_export latex
The summary structure consists of four elements. The start and end of
the merged intervals, the number of mismatches in that given interval,
and the label of the winner subject, or subjects, IDs.
#+end_export
#+begin_src go <<Types, Ch. \ref{ch:alf}>>=
  type Summary struct {
	  start int
	  end int
	  nm float64
	  label []int
  }
#+end_src
#+begin_export latex
To evaluate if two consecutive windows have the same label, we create
a new variable prev to hold the contents of the previous window. Then
we iterate over the range of existing windows. If the variable prev is
empty we store the information of the current window to it. Otherwise,
we check if the slice of subject IDs is identical. If yes, we set the
ending of the new interval as the new interval end. Otherwise we store
the new summarize interval. At the end we also store the final
interval.
#+end_export
#+begin_src go <<Merge adjacent windows, Ch. \ref{ch:alf}>>= 
  var prev *Summary
  for _, win := range windows {
	  for _, w := range win {
		  if prev == nil {
			  prev = &Summary{
				  start: w.start,
				  end: w.end,
				  label: w.winner}
		  } else if slices.Equal(w.winner,
			  prev.label){
			  prev.end = w.end
		  } else  {
			  prev = &Summary{
				  start: w.start,
				  end: w.end,
				  label: w.winner}
			  summary = append(summary,
				  prev)
		  }
	  }
  }
  if prev != nil {
	  summary = append(summary,prev)
  }
#+end_src
#+begin_export latex
We import \ty{slices}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
  "slices"
#+end_src
#+begin_export latex
Finally, we need to calculate the number of mismatches found per
interval as a measure of distance. Given the start and ending point of
each interval, we count the number of existing mismatches, stored in
the mismatches array, in that specific interval. The distance score is
the number of mismatches per bp.
#+end_export
#+begin_src go <<Calculate window mismatches, Ch. \ref{ch:alf}>>=
  for _, sum := range summary {
	  var len int
	  var nm int
	  len = sum.end-sum.start+1
	  for a := sum.start; a <= sum.end; a++ {
		  if mismatches[a] == 1 {
			  nm ++
		  }
	  }
	  sum.nm= float64(nm)/float64(len)
  }
#+end_src
#+begin_export latex
All that is left is to write the output table. We first print the
header, and then parse the subject IDs names and print them out.
#+end_export
#+begin_src go <<Prepare output table, Ch. \ref{ch:alf}>>=
  fmt.Printf("#Query %s\n>Sequence: %s\n" ,
	  query.name,sequence.name)
  for _,sum := range summary {
	  //<<Convert numeric IDs to names, Ch. \ref{ch:alf}>>
	  //<<Print intervals, Ch. \ref{ch:alf}>>
  }
#+end_src
#+begin_export latex
We import \ty{fmt}.
#+end_export
#+begin_src go <<Imports, Ch. \ref{ch:alf}>>=
"fmt"
#+end_src
#+begin_export latex
To convert the numeric IDs to the subject names, we iterate over the
slice of IDs. If the ID is negative, then we are looking at a unique
region and we print ``non-homologous'' in the window annotation. If
the ID is positive then we are standing before a true annotation. So
we extract the corresponding subject Name saved in the subjectNames
map previously constructed and remove the extension of the subject
file. The slice of converted names is then saved.
#+end_export
#+begin_src go <<Convert numeric IDs to names, Ch. \ref{ch:alf}>>=
  str := make([]string, len(sum.label))
  for i, val := range sum.label {
	  var name string
	  if val < 0 {
		  name = "non-homologous"
	  } else {
	  name = strconv.Itoa(val)
	  name = sequence.subjectNames[val]
	  //<<Clean subject name extension, Ch. \ref{ch:alf}>>
	  }
	  str[i] = fmt.Sprintf("%v", name)
  }
#+end_src
#+begin_export latex
To remove the extension of the filenames, we just obtain the index of
the last substring, delimited by a dot, and slice the string up to
that point.
#+end_export
#+begin_src go <<Clean subject name extension, Ch. \ref{ch:alf}>>=
  e := strings.LastIndex(name, ".")
  name = name[:e]
#+end_src
#+begin_export latex
To print the intervals we just iterate through the list of stored
windows. Then we print the left and right borders, both inclusive, the
cumulative match length score, the score per base pair and the slice
of subject IDs separated by comma. We also convert the 0-base
coordinates system into 1-based.
#+end_export
#+begin_src go <<Print intervals, Ch. \ref{ch:alf}>>=
  fmt.Printf("%d\t%d\t%.3f\t%v\n",
	  sum.start+1, sum.end+1,
	  sum.nm, strings.Join(str,","))
#+end_src
#+begin_export latex
\section{Testing}

We have now finished writing alfy, and move on to testing it. The
program to test alfy has hooks for imports and the testing logic.
#+end_export
#+begin_src go <<alfy_test.go>>=
  package main

  import(
	  //<<Testing imports, Ch. \ref{ch:alf}>>
  )

  func TestAlfy(t *testing.T) {
	  //<<Testing, Ch. \ref{ch:alf}>>
  }
#+end_src
#+begin_export latex
We import \ty{testing}.
#+end_export
#+begin_src go <<Testing imports, Ch. \ref{ch:alf}>>=
"testing"
#+end_src
#+begin_export latex
We construct a set of tests, and iterate over them.
#+end_export
#+begin_src go <<Testing, Ch. \ref{ch:alf}>>=
  var tests []*exec.Cmd
  //<<Construct tests, Ch. \ref{ch:alf}>>
  for i, test := range tests {
	  //<<Run test, Ch. \ref{ch:alf}>>
  }
#+end_src
#+begin_export latex
We import \ty{exec}.
#+end_export
#+begin_src go <<Testing imports, Ch. \ref{ch:alf}>>=
"os/exec"
#+end_src
#+begin_export latex
In the first test, we run alfy a window size of 5, half the length of
the test sequence.
#+end_export
#+begin_src go <<Construct tests, Ch. \ref{ch:alf}>>=
  p := "./alfy"
  f := "prep.out"
  w := "5"
  test := exec.Command(p, "-f", f, "-w", w)
  tests = append(tests, test)
#+end_src
#+begin_export latex
In a second test, we test again a window size of 5, but with a reduced
quantile of 0.01.
#+end_export
#+begin_src go <<Construct tests, Ch. \ref{ch:alf}>>=
  q := "0.01"
  test = exec.Command(p, "-f", f, "-w", w, "-q", q)
  tests = append(tests, test)
#+end_src
#+begin_export latex
In a third test, we test with a window size of 10, the length of the
testing sequence, and the default quantile.
#+end_export
#+begin_src go <<Construct tests, Ch. \ref{ch:alf}>>=
  w = "10"
  q = "0.1"
  test = exec.Command(p, "-f", f, "-w", w, "-q", q)
  tests = append(tests, test)
#+end_src
#+begin_export latex
When running a test, we compare the output we get with the one we
want, which is stored in the files r1.txt to r3.txt.
#+end_export
#+begin_src go <<Run test, Ch. \ref{ch:alf}>>=
  //<<Read test output, Ch. \ref{ch:alf}>>
  //<<Read test input, Ch. \ref{ch:alf}>>
  if !bytes.Equal(get, want) {
	  t.Errorf("get:\n%s\nwant:\n%s\n", get, want)
  }
#+end_src
#+begin_export latex
We import \ty{bytes}.
#+end_export
#+begin_src go <<Testing imports, Ch. \ref{ch:alf}>>=
"bytes"
#+end_src
#+begin_export latex
We read the output from \ty{alfy}.
#+end_export
#+begin_src go <<Read test output, Ch. \ref{ch:alf}>>=
  get, err := test.Output()
  if err != nil {
	  t.Error(err)
  }
#+end_src
#+begin_export latex
We read the content of the results files, r\*.txt.
#+end_export
#+begin_src go <<Read test input, Ch. \ref{ch:alf}>>=
  r := "r" + strconv.Itoa(i+1) + ".txt"
  want, err := os.ReadFile(r)
  if err != nil {
	  t.Error(err)
  }
#+end_src
#+begin_export latex
We import \ty{strconv} and \ty{os}.
#+end_export
#+begin_src go <<Testing imports, Ch. \ref{ch:alf}>>=
"strconv"
"os"
#+end_src
