#+begin_export latex
Alfy is a program for alignment-free detection of local homology
between DNA sequences~\cite{dom11:ali}. It takes as input one query
sequence and one or more subject sequences. Its output is a set of
intervals covering the query, the name of the most closely related
subject sequence per interval, if any, and a score of the local
homology.

Figure~\ref{fig:alf} illustrates this for a 10\,kb query that is a
recombinant of two subject sequences. The recombination event is very
recent, so from position 1--4,500 the query is an exact match to
subject $s_1$, for the next 1\,kb it is an exact match to $s_2$,
before it switches back to $s_1$. Correspondingly, in the boxed output
in Figure~\ref{fig:alf} interval 1--4500 is annotated $s_1$, interval
4501--5500 $s_2$, and interval 4501--10,000 $s_1$ again. The fourth
column in the output gives the score, which is the average match
length. Since the recombination is recent, almost all matches extend
to the end of their matching interval. Let the length of that interval
be $\ell$; then the average match length is roughly
$\ell(\ell-1)/2/\ell\approx\ell/2$.

\begin{figure}
  \begin{center}
    \input{../intro/pic}
  \end{center}
  \vspace{0.3cm}
  \begin{center}
    \fbox{
      \begin{minipage}{5cm}
        $>\ty{q}$\\
        \begin{tabular}{rrcr}
          \ty{1} &  \ty{4500} & \ty{s1} & \ty{1250}\\
       \ty{4501} &  \ty{5500} & \ty{s2} & \ty{500}\\
       \ty{5501} & \ty{10000} & \ty{s1} & \ty{1250}
       \end{tabular}
    \end{minipage}
    }
  \end{center}
  \caption{One 10\,kb query, $q$, and two subjects, $s_1$ and $s_2$,
    as input for Alfy, and the corresponding boxed
    output.}\label{fig:alf}
\end{figure}
#+end_export
#+begin_export latex
\section{Alfy v1.6}
Up to version v1.6 Alfy was written in C and had issues that we wish
to address in a re-implementation in Go. The first issue is the
dependence of Alfy on the deep-shallow algorithm for constructing
suffix arrays~\cite{man02:eng}. This algorithm has been superseded by
more efficient alternatives, we shall use the divsufsort
algorithm~\cite{fis17:dis}.

A more fundamental problem with Alfy v1.6 is that its results, though
qualitatively useful, are numerically not correct. To see that, let's
simulate the scenario sketched in Figure~\ref{fig:alf} by first
simulating two subject sequences from which we construct the query.
#+end_export
#+begin_src sh <<intro.sh>>=
  ##<<Construct two subject sequences, Ch. \ref{ch:int}>>
  ##<<Construct query from subject sequences, Ch. \ref{ch:int}>>
#+end_src
#+begin_export latex
We use the program \ty{ms}~\cite{hud02:gen} to simulate two haplotyes
10\,kb long with 100 SNPs. These haplotypes are converted into DNA
sequences by the program \ty{ms2dna}. We save its output in the file
\ty{sbjct.fasta}.
#+end_export
#+begin_src sh <<Construct two subject sequences, Ch. \ref{ch:int}>>=
  ms 2 1 -s 100 -r 0 10000 |
      ms2dna > sbjct.fasta
#+end_src
#+begin_export latex
We construct the query from the subject sequences in four
steps. First, we create the file \ty{query.fasta} and set the header
for our query sequence.
#+end_export
#+begin_src sh <<Construct query from subject sequences, Ch. \ref{ch:int}>>=
  echo ">q" > query.fasta
#+end_src
#+begin_export latex
Then we cut the first 4500\,bp from $s_1$, strip its header, and
append the rest to \ty{query.fasta}.
#+end_export
#+begin_src sh <<Construct query from subject sequences, Ch. \ref{ch:int}>>=
  getSeq S1 sbjct.fasta |
      cutSeq -r 1-4500 |
      tail -n +2 >> query.fasta
#+end_src
#+begin_export latex
In the third step we cut the middle 1\,kb from $s_2$, strip its
header, and append it to \ty{query.fasta}.
#+end_export
#+begin_src sh <<Construct query from subject sequences, Ch. \ref{ch:int}>>=
  getSeq S2 sbjct.fasta |
      cutSeq -r 4501-5500 |
      tail -n +2 >> query.fasta
#+end_src
#+begin_export latex
In the fourth and final step, we return to $s_1$, excise its rightmost
4500\,bp, strip its header, and append it to \ty{query.fasta}.
#+end_export
#+begin_src sh <<Construct query from subject sequences, Ch. \ref{ch:int}>>=
  getSeq S1 sbjct.fasta |
      cutSeq -r 5501-10000 |
      tail -n +2 >> query.fasta
#+end_src
#+begin_export latex
We run Alfy v1.6 and format its output into neat columns using the
program \ty{column} in table mode. This gives the tripartite structure
of the query, albeit with a left-shift in the localization of the
insertion by roughly 1/2 the default window length of 300\,bp.
#+end_export
#+begin_src sh <<intro.sh>>=
  alfy -i query.fasta -j sbjct.fasta |
      column -t
#+end_src
#+begin_export latex
\begin{verbatim}
>q
1     4275   2378.556396  S1
4276  5295   662.116760   S2
5296  10000  2237.917725  S1
\end{verbatim}
So far so good. However, it is possible to find scenarios where the
score of an interval returned by Alfy is zero. Clearly, given subject
sequences of non-trivial length, any query position has a match. So an
interval with average match length of zero must be due to an error in
the calculation. Let's construct a configuration of sequences that
reproduces this bug. When we played around with various parameter
combinations, we could only do this with at least three subject
sequences and further mutating the query sequence. So we simulate
three subject sequences, construct the query from $s_1$ and $s_2$ as
before, and mutate it.
#+end_export
#+begin_src sh <<intro.sh>>=
  ##<<Construct three subject sequences, Ch. \ref{ch:int}>>
  ##<<Construct query from subject sequences, Ch. \ref{ch:int}>>
  ##<<Mutate query, Ch. \ref{ch:int}>>
#+end_src
#+begin_export latex
Our simulations are all stochastic, so in order to get the desired
result, we need to seed the random number generators used in the
programs \ty{ms}, \ty{ms2dna}, and \ty{mutator}. For the latter two we
just use their \ty{-s} option. The program \ty{ms}, however, reads its
seed from a file called \ty{seedms}. The desired seed is contained in
file \ty{seedms3}, which we copy to \ty{seedms}. For \ty{ms2dna} we
set the seed to 3.
#+end_export
#+begin_src sh <<Construct three subject sequences, Ch. \ref{ch:int}>>=
  cp seedms3 seedms
  ms 3 1 -s 200 -r 0 10000 |
      ms2dna -s 3 > sbjct.fasta
#+end_src
#+begin_export latex
We mutate the query with the program \ty{mutator}, where we also seed
the random number generator to 3.
#+end_export
#+begin_src sh <<Mutate query, Ch. \ref{ch:int}>>=
mutator -s 3 query.fasta > t
mv t query.fasta
#+end_src
#+begin_export latex
When we now run Alfy v1.6, we find a region with the impossible
average match length zero.
#+end_export
#+begin_src sh <<intro.sh>>=
  alfy -w 100 -i query.fasta -j sbjct.fasta |
      column -t |
      awk '$3==0'
#+end_src
#+begin_export latex
\begin{verbatim}
7316  7360   0.000000    S2  S1
\end{verbatim}
\section{Reimplementation}
\subsection{Algorithm}
Algorithm~\ref{alg:alf} shows a sketch of the method at the heart of
our reimplementation of Alfy. It is essentially the algorithm used in
Fur to find unique regions from match lengths~\cite{vie24:mar}. The
most significant change is that for Alfy we augment the iterative
recording of match lengths used in Fur by also recording the subject
containing each match.

\begin{algorithm}
\caption{Finding the longest matches between a query sequence and a set of subject sequences.}\label{alg:alf}
  \begin{algorithmic}[1]
    \REQUIRE $q$, query sequence length $m$
    \REQUIRE $\mbox{subjects}$, array of $n$ subject sequences
    \ENSURE $\mbox{ml}$, array of $m$ longest match lengths of $q$
    w.r.t. all subjects; initialized to -1
    \ENSURE $\mbox{su}$, subjects containing the longest match
    lengths; initialized to 0
    \FOR{$i\leftarrow 1$ \TO $n$}
       \STATE $s\leftarrow\mbox{getEsa}(\mbox{subjects}[i])$
       \STATE $j\leftarrow 1$
       \WHILE{$j\le m$}
          \STATE $\ell\leftarrow s.\mbox{MatchPrefix}(q[j:])$
          \IF{$\mbox{ml}[j]<\ell$}
             \STATE $\mbox{ml}[j]\leftarrow\ell$
             \STATE $\mbox{su}[j]\leftarrow i$
          \ENDIF
          \STATE $j\leftarrow j + \ell + 1$
       \ENDWHILE
       \STATE $\mbox{interpolate}(\mbox{ml},\mbox{su})$
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

For a given query sequence of length $m$, $q$, the algorithm iterates
over the subjects and first converts a given subject to its enhanced
suffix array, $s$ (line 2). Then we initialize the matching start in
$q$, $j$, to 1 (line 3). With these preparations out of the way, we
iterate across $q$ and calculate an array of longest match lengths,
$\mbox{ml}$, and an array of subjects inducing these lengths,
$\mbox{su}$.

For a given subject labeled $i$, the matching starts at the first
position of $q$, $q[1]$, and ends just before the first mismatch at
$q[\ell+1]$. If $\ell$ is greater than the longest match found so fart
at $q[1]$, $\mbox{ml}[1]$ is updated to $\ell$ and $\mbox{su}[1]$ to
$i$ (lines 6--9). Then the matching start, $j$, skips to the first
position beyond the terminating mismatch, $j\leftarrow 1+\ell+1$, and
the analysis repeats (lines 10 and 11).

Once the query has been traversed, the match lengths are interpolated
as shown in Algorithm~\ref{alg:int}. At each position $\mbox{ml}[i]$
the match to its left, $\mbox{ml}[i-1]$ is extended, unless we are at
the start of a new match.

\begin{algorithm}
  \caption{Interpolation of match lengths and subject
    indexes}\label{alg:int}
  \begin{algorithmic}
    \REQUIRE $\mbox{ml}$, array of $m$ match lengths
    \REQUIRE $\mbox{su}$, array of $m$ subject indexes
    \ENSURE $\mbox{ml}$ and $\mbox{su}$ are complete
    \FOR{$i\leftarrow 2$ \TO $m$}
       \STATE $x\leftarrow \mbox{ml}[i-1]-1$
       \IF{$x>\mbox{ml}[i]$}
          \STATE $\mbox{ml}[i]\leftarrow x$
          \STATE $\mbox{su}[i]\leftarrow\mbox{su}[i-1]$
       \ENDIF
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

The arrays of match lengths and subject indexes are later used to
cover $q$ with intervals of closest relatives among the subjects.

\subsection{User Perspective}
The program \ty{alfy} consists of matching and a sliding window
analysis of the result of the matching. Since the sliding window
analysis might be run repeatedly on the same matching result, it is a
good idea to separate it from the time-consuming matching step. Since
the matching can be seen as preparation for the sliding window
analysis, we call the two programs \ty{prepAlfy} and \ty{alfy}. The
user should be able to run them as a pipeline,
\begin{verbatim}
prepAlfy -q queries/ -s subjects/ | alfy
\end{verbatim}
or as separate steps,
\begin{verbatim}
prepAlfy -q queries/ -s subjects/ > alfy.in
alfy alfy.in
\end{verbatim}

The program \ty{prepAlfy} takes as mandatory options \ty{-q} and
\ty{-s}, which specify the directories of query and subject FASTA
files, respectively. The structure here is the same as the switches
for targets and neighbors in \ty{makeNeiDb}. The output of
\ty{prepAlfy} is a table with two columns for each query consisting of
the query name, followed by pairs of match lengths and subject
identifiers,
\begin{verbatim}
#q1
50 1
49 1
48 1
...
#q2
34 5
33 5
32 5
...
\end{verbatim}
The tables are understood to cover every position in the respective
query.

\subsection{Coding}
The subpackage \ty{mat} contains the function \ty{Match}, which takes
as argument a query sequence, and the ESA of a subject sequence. It
then carries out lines 3--10 of Algorithm~\ref{alg:alf} and returns
two arrays, match lengths, $\mbox{ml}$, and subject identifiers,
$\mbox{su}$.
#+end_export
